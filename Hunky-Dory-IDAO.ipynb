{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ihar/catboost/catboost/python-package/catboost/./_catboost.so']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "\n",
    "SIMPLE_FEATURE_COLUMNS_FLOAT = ['ncl[0]', 'ncl[1]', 'ncl[2]', 'ncl[3]', 'avg_cs[0]',\n",
    "       'avg_cs[1]', 'avg_cs[2]', 'avg_cs[3]',\n",
    "       'MatchedHit_X[0]', 'MatchedHit_X[1]', 'MatchedHit_X[2]',\n",
    "       'MatchedHit_X[3]', 'MatchedHit_Y[0]', 'MatchedHit_Y[1]',\n",
    "       'MatchedHit_Y[2]', 'MatchedHit_Y[3]', 'MatchedHit_Z[0]',\n",
    "       'MatchedHit_Z[1]', 'MatchedHit_Z[2]', 'MatchedHit_Z[3]',\n",
    "       'MatchedHit_DX[0]', 'MatchedHit_DX[1]', 'MatchedHit_DX[2]',\n",
    "       'MatchedHit_DX[3]', 'MatchedHit_DY[0]', 'MatchedHit_DY[1]',\n",
    "       'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[0]',\n",
    "       'MatchedHit_DZ[1]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]',\n",
    "       'MatchedHit_T[0]', 'MatchedHit_T[1]', 'MatchedHit_T[2]',\n",
    "       'MatchedHit_T[3]', 'MatchedHit_DT[0]', 'MatchedHit_DT[1]',\n",
    "       'MatchedHit_DT[2]', 'MatchedHit_DT[3]', 'Lextra_X[0]', 'Lextra_X[1]',\n",
    "       'Lextra_X[2]', 'Lextra_X[3]', 'Lextra_Y[0]', 'Lextra_Y[1]',\n",
    "       'Lextra_Y[2]', 'Lextra_Y[3]', 'NShared', 'Mextra_DX2[0]',\n",
    "       'Mextra_DX2[1]', 'Mextra_DX2[2]', 'Mextra_DX2[3]', 'Mextra_DY2[0]',\n",
    "       'Mextra_DY2[1]', 'Mextra_DY2[2]', 'Mextra_DY2[3]', 'FOI_hits_N', 'PT', 'P',\n",
    "                         ]\n",
    "\n",
    "TRAIN_COLUMNS = [\"label\", \"weight\", \"particle_type\", 'sWeight', 'kinWeight']\n",
    "\n",
    "FOI_COLUMNS = [\"FOI_hits_X\", \"FOI_hits_Y\", \"FOI_hits_T\",\n",
    "               \"FOI_hits_Z\", \"FOI_hits_DX\", \"FOI_hits_DY\", \"FOI_hits_S\"]\n",
    "\n",
    "\n",
    "\n",
    "SIMPLE_FEATURE_COLUMNS = ['ncl[0]', 'ncl[1]', 'ncl[2]', 'ncl[3]', 'avg_cs[0]',\n",
    "       'avg_cs[1]', 'avg_cs[2]', 'avg_cs[3]', 'ndof', \n",
    "                          'MatchedHit_TYPE[0]',\n",
    "       'MatchedHit_TYPE[1]', 'MatchedHit_TYPE[2]', 'MatchedHit_TYPE[3]',\n",
    "       'MatchedHit_X[0]', 'MatchedHit_X[1]', 'MatchedHit_X[2]',\n",
    "       'MatchedHit_X[3]', 'MatchedHit_Y[0]', 'MatchedHit_Y[1]',\n",
    "       'MatchedHit_Y[2]', 'MatchedHit_Y[3]', 'MatchedHit_Z[0]',\n",
    "       'MatchedHit_Z[1]', 'MatchedHit_Z[2]', 'MatchedHit_Z[3]',\n",
    "       'MatchedHit_DX[0]', 'MatchedHit_DX[1]', 'MatchedHit_DX[2]',\n",
    "       'MatchedHit_DX[3]', 'MatchedHit_DY[0]', 'MatchedHit_DY[1]',\n",
    "       'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[0]',\n",
    "       'MatchedHit_DZ[1]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]',\n",
    "       'MatchedHit_T[0]', 'MatchedHit_T[1]', 'MatchedHit_T[2]',\n",
    "       'MatchedHit_T[3]', 'MatchedHit_DT[0]', 'MatchedHit_DT[1]',\n",
    "       'MatchedHit_DT[2]', 'MatchedHit_DT[3]', 'Lextra_X[0]', 'Lextra_X[1]',\n",
    "       'Lextra_X[2]', 'Lextra_X[3]', 'Lextra_Y[0]', 'Lextra_Y[1]',\n",
    "       'Lextra_Y[2]', 'Lextra_Y[3]', 'NShared', 'Mextra_DX2[0]',\n",
    "       'Mextra_DX2[1]', 'Mextra_DX2[2]', 'Mextra_DX2[3]', 'Mextra_DY2[0]',\n",
    "       'Mextra_DY2[1]', 'Mextra_DY2[2]', 'Mextra_DY2[3]',\n",
    "                          'FOI_hits_N', 'PT', 'P']\n",
    "\n",
    "FOI_COLUMNS = [\"FOI_hits_X\", \"FOI_hits_Y\", \"FOI_hits_T\",\n",
    "               \"FOI_hits_Z\", \"FOI_hits_DX\", \"FOI_hits_DY\", \"FOI_hits_S\"]\n",
    "\n",
    "ID_COLUMN = \"id\"\n",
    "\n",
    "N_STATIONS = 4\n",
    "FEATURES_PER_STATION = 6\n",
    "N_FOI_FEATURES = N_STATIONS*FEATURES_PER_STATION\n",
    "# The value to use for stations with missing hits\n",
    "# when computing FOI features\n",
    "EMPTY_FILLER = 1000\n",
    "\n",
    "# Examples on working with the provided files in different ways\n",
    "\n",
    "VERSION = \"v2\"\n",
    "# hdf is all fine - but it requires unpickling the numpy arrays\n",
    "# which is not guranteed\n",
    "def load_train_hdf(path):\n",
    "    return pd.concat([\n",
    "        pd.read_hdf(os.path.join(path, \"train_part_%i_%s.hdf\" % (i, VERSION)))\n",
    "        for i in (1, 1)], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def load_data_csv(path, feature_columns= [ID_COLUMN] + SIMPLE_FEATURE_COLUMNS):\n",
    "    converters = dict(zip(FOI_COLUMNS, repeat(parse_array)))\n",
    "    types = dict(zip(SIMPLE_FEATURE_COLUMNS, repeat(np.float32)))\n",
    "    train = pd.concat([\n",
    "        pd.read_csv(os.path.join(path, \"train_part_%i_%s.csv.gz\" % (i, VERSION)),\n",
    "                    usecols= [ID_COLUMN] + feature_columns + TRAIN_COLUMNS,\n",
    "                       dtype=types,\n",
    "                    index_col=ID_COLUMN)\n",
    "        for i in (1, 2)], axis=0, ignore_index=True)\n",
    "    test = pd.read_csv(os.path.join(path, \"test_private_%s_track_1.csv\" % VERSION),\n",
    "                       dtype=types,\n",
    "                       usecols=[ID_COLUMN] + feature_columns, index_col=ID_COLUMN)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def parse_array(line, dtype=np.float32):\n",
    "    return np.fromstring(line[1:-1], sep=\" \", dtype=dtype)\n",
    "\n",
    "\n",
    "def load_full_test_csv(path):\n",
    "    converters = dict(zip(FOI_COLUMNS, repeat(parse_array)))\n",
    "    types = dict(zip(SIMPLE_FEATURE_COLUMNS, repeat(np.float32)))\n",
    "    test = pd.read_csv(os.path.join(path, \"test_public_%s.csv.gz\" % VERSION),\n",
    "                       index_col=\"id\", converters=converters,\n",
    "                       dtype=types,\n",
    "                       usecols=[ID_COLUMN]+SIMPLE_FEATURE_COLUMNS+FOI_COLUMNS)\n",
    "    return test\n",
    "\n",
    "\n",
    "def find_closest_hit_per_station(row):\n",
    "    result = np.empty(N_FOI_FEATURES, dtype=np.float32)\n",
    "    closest_x_per_station = result[0:4]\n",
    "    closest_y_per_station = result[4:8]\n",
    "    closest_T_per_station = result[8:12]\n",
    "    closest_z_per_station = result[12:16]\n",
    "    closest_dx_per_station = result[16:20]\n",
    "    closest_dy_per_station = result[20:24]\n",
    "    \n",
    "    for station in range(4):\n",
    "        hits = (row[\"FOI_hits_S\"] == station)\n",
    "        if not hits.any():\n",
    "            closest_x_per_station[station] = EMPTY_FILLER\n",
    "            closest_y_per_station[station] = EMPTY_FILLER\n",
    "            closest_T_per_station[station] = EMPTY_FILLER\n",
    "            closest_z_per_station[station] = EMPTY_FILLER\n",
    "            closest_dx_per_station[station] = EMPTY_FILLER\n",
    "            closest_dy_per_station[station] = EMPTY_FILLER\n",
    "        else:\n",
    "            x_distances_2 = (row[\"Lextra_X[%i]\" % station] - row[\"FOI_hits_X\"][hits])**2\n",
    "            y_distances_2 = (row[\"Lextra_Y[%i]\" % station] - row[\"FOI_hits_Y\"][hits])**2\n",
    "            distances_2 = x_distances_2 + y_distances_2\n",
    "            closest_hit = np.argmin(distances_2)\n",
    "            closest_x_per_station[station] = x_distances_2[closest_hit]\n",
    "            closest_y_per_station[station] = y_distances_2[closest_hit]\n",
    "            closest_T_per_station[station] = row[\"FOI_hits_T\"][hits][closest_hit]\n",
    "            closest_z_per_station[station] = row[\"FOI_hits_Z\"][hits][closest_hit]\n",
    "            closest_dx_per_station[station] = row[\"FOI_hits_DX\"][hits][closest_hit]\n",
    "            closest_dy_per_station[station] = row[\"FOI_hits_DY\"][hits][closest_hit]\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihar/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "full_train, test = load_data_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihar/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Can be calculated using find_closest_hit_per_station function for test data\n",
    "\n",
    "closest_hits_features_test = pd.read_csv('private_features.csv', index_col=0, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_concat = pd.concat(\n",
    "    [test.loc[:, SIMPLE_FEATURE_COLUMNS],\n",
    "     closest_hits_features_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1452188, 89)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ihar/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Can be calculated using find_closest_hit_per_station function for train data\n",
    "closest_hits_features = pd.read_csv('closest_hits_features.csv', index_col=0, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = pd.concat(\n",
    "    [full_train.loc[:, SIMPLE_FEATURE_COLUMNS],,\n",
    "     closest_hits_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 5445705\n",
    "ntest = 1452188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_concat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "X_train_sklearn = []\n",
    "X_test_sklearn = []\n",
    "X_emb_sklearn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sklearn = np.array(X_train[:ntrain])\n",
    "X_test_sklearn = np.array(X_train[ntrain:])\n",
    "Y_train = full_train.particle_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = full_train.particle_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d19ad43d7df445cae86198fbfba478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=48, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weight_train = full_train.weight.swifter.apply(lambda x: x if x > 0 else 0).values\n",
    "weight_train_original = full_train.weight.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.utils import class_weight\n",
    "import scoring\n",
    "import gc\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def metric(y_true, y_pred, sample_weight):\n",
    "    return scoring.rejection90(y_true, y_pred, sample_weight=sample_weight)\n",
    "                                        \n",
    "my_scorer = make_scorer(metric, greater_is_better=True)\n",
    "\n",
    "def unison_shuffled_copies(a, b, c, d):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p], d[p]\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "y = []\n",
    "weight_train_original_shuffle = []\n",
    "test_index = []\n",
    "\n",
    "# Uncomment to shuffle data\n",
    "\n",
    "# X_train_shuffle, Y_train_shuffle, weight_train_shuffle, \\\n",
    "#         weight_train_original_shuffle = unison_shuffled_copies(X_train_sklearn, Y_train, weight_train,\\\n",
    "#                                                              weight_train_original)\n",
    "X_train_shuffle, Y_train_shuffle, weight_train_shuffle, \\\n",
    "        weight_train_original_shuffle    = X_train_sklearn, Y_train, weight_train,\\\n",
    "                                                             weight_train_original\n",
    "def rmsle_cv(model_class):\n",
    "    \"\"\"\n",
    "    A function to test a model performance using k-fold cross validation\n",
    "    \"\"\"\n",
    "    global y_pred, y, weight_train_original_shuffle, test_index\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_folds, shuffle=True)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X_train_sklearn):\n",
    "        gc.collect()\n",
    "        X, y = X_train_shuffle[train_index], Y_train_shuffle[train_index]\n",
    "        sample_weight = weight_train_shuffle[train_index]\n",
    "        \n",
    "        \n",
    "        class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y),\n",
    "                                                 y)\n",
    "   \n",
    "        X_train, y_train = X.copy(), y.copy()\n",
    "        model = model_class(class_weights)\n",
    "        \n",
    "        if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "            y_train[y_train == 2] = 0\n",
    "            \n",
    "    \n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        X, y = X_train_shuffle[test_index], Y_train_shuffle[test_index]\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "        y[y == 2] = 0\n",
    "        score = metric(y, y_pred,  weight_train_original_shuffle[test_index])\n",
    "        scores.append(score)\n",
    "        print(score)\n",
    "  \n",
    "        \n",
    "    return(np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "model_lgb = lambda class_weights: lgb.LGBMClassifier(\n",
    "    num_leaves=200,\n",
    "    learning_rate=0.1, n_estimators=1500,\n",
    "    bagging_fraction = 0.8,\n",
    "    bagging_freq = 3, feature_fraction = 0.8,\n",
    "    min_data_in_leaf=800,\n",
    "    device='gpu',\n",
    "    # is_unbalance=True,\n",
    "    metrics=['acc'],\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    bagging_temperature=0.15,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check lgbm performance\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "try:\n",
    "    model_cat = lambda class_weights: catboost.CatBoostClassifier(task_type='CPU', class_weights=None,\n",
    "                                            iterations=1300, max_depth=5, thread_count=12, verbose=True,\n",
    "                                                         l2_leaf_reg=None, \n",
    "                                                              # bagging_temperature=0.12,\n",
    "                                                           border_count=52,\n",
    "                                                                  boosting_type='Plain',\n",
    "                                                                  max_ctr_complexity=1,\n",
    "                                                         )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "score = rmsle_cv(model_cat)\n",
    "print(\"CatBoost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models, class_weights):\n",
    "        self.models = models\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        y_new = y.copy()\n",
    "        self.models_ = [x(self.class_weights) for x, _ in self.models]\n",
    "        self.weights = [weight for _, weight in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            print(model.__class__.__name__)\n",
    "            if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "                y_new[y_new == 2] = 0\n",
    "                print(y_new)\n",
    "            model.fit(X, y_new,\n",
    "                      sample_weight=sample_weight)\n",
    "            if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "                model.save_model(\"model_cat_avg.cbm\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # Now we do the predictions for cloned models and average them\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        sum_weight = 0\n",
    "        for weight in self.weights:\n",
    "            sum_weight += weight\n",
    "            \n",
    "        predictions = np.add(*[\n",
    "            model.predict_proba(X) * (self.weights[i] / sum_weight) for i, model in enumerate(self.models_)\n",
    "        ])\n",
    "        return predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_models = lambda class_weights: AveragingModels(models = ((model_cat, 1), (model_lgb, 1)),\n",
    "                                                        class_weights=class_weights)\n",
    "\n",
    "# score = rmsle_cv(averaged_models)\n",
    "# print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat = lambda class_weights: catboost.CatBoostClassifier(task_type='GPU', class_weights=None,\n",
    "                                            iterations=1300, max_depth=5, thread_count=12, verbose=True,\n",
    "                                                         l2_leaf_reg=None, bagging_temperature=0.12,\n",
    "                                                         )\n",
    "\n",
    "averaged_models = lambda class_weights: AveragingModels(models = ((model_cat, 1), (model_lgb, 1)),\n",
    "                                                        class_weights=class_weights)\n",
    "model = averaged_models(None)\n",
    "\n",
    "X, y = X_train_sklearn, Y_train\n",
    "\n",
    "if model.__class__.__name__ == 'CatBoostClassifier':\n",
    "    y[y == 2] = 0\n",
    "\n",
    "sample_weight_train = weight_train\n",
    "model.fit(X, y, sample_weight=sample_weight_train)\n",
    "y_pred = model.predict_proba(test_concat.values)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\"prediction\": y_pred}, index=test.index).to_csv(\n",
    "    \"submission30_final.csv\", index_label=ID_COLUMN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
